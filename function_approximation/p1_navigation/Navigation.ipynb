{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Banana.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "step_count = 1\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    step_count+=1\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score),\" steps \",step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple, deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 999999 #\n",
    "MAX_STEPS = 200000\n",
    "START_EPSILON = 1.0\n",
    "END_EPSILON = 0.01\n",
    "EPSILON_DECAY = 0.99125\n",
    "UPDATE_TARGET_NETWORK_EVERY = 50\n",
    "REPLAY_BUFFER_SIZE = 100000\n",
    "TRAIN_EVERY  = 4\n",
    "BATCH_SIZE = 32\n",
    "PRINT_EVERY = 10\n",
    "LEARNING_RATE = 0.00025\n",
    "VISUALIZE_EVERY = 100 #visualize the agent in the unity environment\n",
    "\n",
    "DESIRED_AVERAGE = 13\n",
    "DESIRED_EPISODES_AVERAGE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples for experience replay\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        #self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self,state_size,action_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        #assert len(hidden_sizes) > 0\n",
    "        self.fc1 = nn.Linear(state_size,150)\n",
    "        #self.hidden_layers = [] # list of nn.Linear\n",
    "        \n",
    "        #for i,size in enumerate(hidden_sizes[1:]):\n",
    "        #    self.hidden_layers.append(nn.Linear(hidden_sizes[i],size))\n",
    "         \n",
    "        self.fc2 = nn.Linear(150,150)\n",
    "        self.output_layer = nn.Linear(150,action_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \n",
    "    def __init__(self,state_size, action_size,lr=0.001):\n",
    "        print(\"agent created\")\n",
    "        self.action_size = action_size\n",
    "        self.q_network_local = QNetwork(state_size,action_size).to(device) #network used to make desicion and with online updates\n",
    "        self.q_network_target = QNetwork(state_size,action_size).to(device) #network to calclate the target (copy of local)\n",
    "        self.q_network_target.eval()\n",
    "        self.optimizer = optim.Adam(self.q_network_local.parameters(),lr =lr) #TODO:ADD lr as parameter\n",
    "        \n",
    "        self.replay_buffer = ReplayBuffer(action_size,REPLAY_BUFFER_SIZE) #TODO: make them variables of constructor\n",
    "        \n",
    "        self.explore_count = 0\n",
    "        self.exploit_count = 0\n",
    "        \n",
    "    def act(self,state,epsilon=0.0):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        random_sampled = np.random.random()\n",
    "        \n",
    "        #explore\n",
    "        if random_sampled <= epsilon:\n",
    "            action = np.random.randint(action_size)\n",
    "            self.explore_count += 1 \n",
    "        else: #exploit\n",
    "            self.q_network_local.eval()\n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network_local(state)\n",
    "                \n",
    "            greedy_action = np.argmax(q_values.cpu().data.numpy())   \n",
    "            action = greedy_action\n",
    "            self.exploit_count += 1\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        for target_param, local_param in zip(self.q_network_target.parameters(), self.q_network_local.parameters()):\n",
    "            target_param.data.copy_(local_param.data )\n",
    "            \n",
    "    def train(self,batch_size):\n",
    "        (states, actions, rewards, next_states, dones) = self.replay_buffer.sample(batch_size)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            local_max_action = self.q_network_local(next_states).detach().argmax(1).unsqueeze(1)\n",
    "            current_target  = rewards + 0.99*self.q_network_target(next_states).gather(dim=1,index=local_max_action)\n",
    "            \n",
    "        self.q_network_local.train()\n",
    "        current_estimate =  self.q_network_local(states).gather(1,actions)\n",
    "        \n",
    "        mse_loss = F.mse_loss(current_target,current_estimate)\n",
    "        self.optimizer.zero_grad()\n",
    "        mse_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def reset_explore_exploit_counts(self):\n",
    "        self.explore_count = 0\n",
    "        self.exploit_count = 0\n",
    "        \n",
    "    def get_explore_explit_counts(self):\n",
    "        return str((self.explore_count,self.exploit_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent created\n",
      "Episode: 0  steps: 300  episode reward: 0.0  epsilon: 1.0  explore,exploit counts: (300, 0)\n",
      "Episode: 10  steps: 300  episode reward: -1.0  epsilon: 0.9158661400249172  explore,exploit counts: (275, 25)\n",
      "Episode: 20  steps: 300  episode reward: 1.0  epsilon: 0.8388107864441411  explore,exploit counts: (256, 44)\n",
      "Episode: 30  steps: 300  episode reward: 2.0  epsilon: 0.7682383971918605  explore,exploit counts: (236, 64)\n",
      "Episode: 40  steps: 300  episode reward: 0.0  epsilon: 0.7036035354550384  explore,exploit counts: (200, 100)\n",
      "Episode: 50  steps: 300  episode reward: 2.0  epsilon: 0.6444066541250909  explore,exploit counts: (182, 118)\n",
      "Episode: 60  steps: 300  episode reward: 4.0  epsilon: 0.5901902349199187  explore,exploit counts: (180, 120)\n",
      "Episode: 70  steps: 300  episode reward: 3.0  epsilon: 0.5405352523365048  explore,exploit counts: (171, 129)\n",
      "Episode: 80  steps: 300  episode reward: 4.0  epsilon: 0.49505793510482926  explore,exploit counts: (151, 149)\n",
      "Episode: 90  steps: 300  episode reward: 9.0  epsilon: 0.4534068001131659  explore,exploit counts: (133, 167)\n",
      "Episode: 100  steps: 300  episode reward: 6.0  epsilon: 0.4152599358806945  explore,exploit counts: (125, 175)\n",
      "Episode: 110  steps: 300  episode reward: 3.0  epsilon: 0.3803225145820462  explore,exploit counts: (113, 187)\n",
      "Episode: 120  steps: 300  episode reward: 2.0  epsilon: 0.34832451339482895  explore,exploit counts: (103, 197)\n",
      "Episode: 130  steps: 300  episode reward: 5.0  epsilon: 0.31901862755897953  explore,exploit counts: (92, 208)\n",
      "Episode: 140  steps: 300  episode reward: 10.0  epsilon: 0.29217835901848915  explore,exploit counts: (89, 211)\n",
      "Episode: 150  steps: 300  episode reward: 13.0  epsilon: 0.2675962658730781  explore,exploit counts: (85, 215)\n",
      "Episode: 160  steps: 300  episode reward: 10.0  epsilon: 0.24508235911025741  explore,exploit counts: (73, 227)\n",
      "Episode: 170  steps: 300  episode reward: 4.0  epsilon: 0.224462634226512  explore,exploit counts: (55, 245)\n",
      "Episode: 180  steps: 300  episode reward: 4.0  epsilon: 0.20557772638886038  explore,exploit counts: (60, 240)\n",
      "Episode: 190  steps: 300  episode reward: 7.0  epsilon: 0.18828167874286414  explore,exploit counts: (57, 243)\n",
      "Episode: 200  steps: 300  episode reward: 12.0  epsilon: 0.17244081434763844  explore,exploit counts: (49, 251)\n",
      "Episode: 210  steps: 300  episode reward: 10.0  epsilon: 0.157932703019325  explore,exploit counts: (47, 253)\n",
      "Episode: 220  steps: 300  episode reward: 12.0  epsilon: 0.14464521509801076  explore,exploit counts: (49, 251)\n",
      "Episode: 230  steps: 300  episode reward: 12.0  epsilon: 0.13247565482488904  explore,exploit counts: (49, 251)\n",
      "Episode: 240  steps: 300  episode reward: 4.0  epsilon: 0.12132996663174446  explore,exploit counts: (38, 262)\n",
      "Episode: 250  steps: 300  episode reward: 7.0  epsilon: 0.1111220082083678  explore,exploit counts: (44, 256)\n",
      "Episode: 260  steps: 300  episode reward: 10.0  epsilon: 0.10177288472961499  explore,exploit counts: (31, 269)\n",
      "Episode: 270  steps: 300  episode reward: 10.0  epsilon: 0.09321033909651333  explore,exploit counts: (30, 270)\n",
      "Episode: 280  steps: 300  episode reward: 7.0  epsilon: 0.0853681934787373  explore,exploit counts: (35, 265)\n",
      "Episode: 290  steps: 300  episode reward: 10.0  epsilon: 0.07818583784227143  explore,exploit counts: (20, 280)\n",
      "Episode: 300  steps: 300  episode reward: 9.0  epsilon: 0.07160776150921523  explore,exploit counts: (20, 280)\n",
      "Episode: 310  steps: 300  episode reward: 14.0  epsilon: 0.06558312412926978  explore,exploit counts: (25, 275)\n",
      "Episode: 320  steps: 300  episode reward: 6.0  epsilon: 0.060065362747049315  explore,exploit counts: (17, 283)\n",
      "Episode: 330  steps: 300  episode reward: 13.0  epsilon: 0.0550118319283365  explore,exploit counts: (21, 279)\n",
      "Episode: 340  steps: 300  episode reward: 10.0  epsilon: 0.05038347416390505  explore,exploit counts: (10, 290)\n",
      "Episode: 350  steps: 300  episode reward: 11.0  epsilon: 0.046144518003540844  explore,exploit counts: (17, 283)\n",
      "Episode: 360  steps: 300  episode reward: 11.0  epsilon: 0.04226220158721325  explore,exploit counts: (11, 289)\n",
      "Episode: 370  steps: 300  episode reward: 14.0  epsilon: 0.03870651943663591  explore,exploit counts: (14, 286)\n",
      "Episode: 380  steps: 300  episode reward: 9.0  epsilon: 0.03544999055023116  explore,exploit counts: (5, 295)\n",
      "Episode: 390  steps: 300  episode reward: 11.0  epsilon: 0.03246744600916001  explore,exploit counts: (14, 286)\n",
      "Episode: 400  steps: 300  episode reward: 10.0  epsilon: 0.029735834452876784  explore,exploit counts: (9, 291)\n",
      "Episode: 410  steps: 300  episode reward: 8.0  epsilon: 0.0272340439207762  explore,exploit counts: (8, 292)\n",
      "Episode: 420  steps: 300  episode reward: 17.0  epsilon: 0.02494273868299036  explore,exploit counts: (7, 293)\n",
      "Episode: 430  steps: 300  episode reward: 11.0  epsilon: 0.02284420979924057  explore,exploit counts: (10, 290)\n",
      "Episode: 440  steps: 300  episode reward: 16.0  epsilon: 0.02092223825074985  explore,exploit counts: (14, 286)\n",
      "Episode: 450  steps: 300  episode reward: 14.0  epsilon: 0.01916196958739594  explore,exploit counts: (12, 288)\n",
      "Episode: 460  steps: 300  episode reward: 19.0  epsilon: 0.01754979912128317  explore,exploit counts: (4, 296)\n",
      "Episode: 470  steps: 300  episode reward: 12.0  epsilon: 0.0160732667794223  explore,exploit counts: (5, 295)\n",
      "Episode: 480  steps: 300  episode reward: 5.0  epsilon: 0.014720960802860233  explore,exploit counts: (1, 299)\n",
      "Episode: 490  steps: 300  episode reward: 14.0  epsilon: 0.013482429547973709  explore,exploit counts: (4, 296)\n",
      "Solved in  494  episodes \n",
      "Last  100  average reward: 13.0\n"
     ]
    }
   ],
   "source": [
    "#env = UnityEnvironment(file_name=\"./Banana_Linux/Banana.x86_64\")\n",
    "agent = Agent(state_size,action_size,LEARNING_RATE)\n",
    "\n",
    "episodes_rewards = []\n",
    "solved = False\n",
    "epsilon = START_EPSILON\n",
    "for episode in range(EPISODES):\n",
    "    finished = False\n",
    "    step_count = 0\n",
    "    episode_score = 0\n",
    "    \n",
    "    agent.reset_explore_exploit_counts()\n",
    "    \n",
    "    train_mode = not (episode % VISUALIZE_EVERY == 0)\n",
    "    env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    \n",
    "    while not finished: #and step_count < MAX_STEPS:\n",
    "        action = agent.act(state,epsilon) \n",
    "\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        finished = env_info.local_done[0]\n",
    "        \n",
    "        # add experience tuple to experience replay buffer\n",
    "        agent.replay_buffer.add(state,action,reward,next_state,finished)\n",
    "        episode_score += reward\n",
    "        state = next_state\n",
    "        \n",
    "        # create a copy of local network to target network\n",
    "        if step_count % UPDATE_TARGET_NETWORK_EVERY == 0:\n",
    "            agent.update_target_network()\n",
    "            \n",
    "            \n",
    "        if step_count % TRAIN_EVERY == 0 and len(agent.replay_buffer) >=  BATCH_SIZE:\n",
    "            agent.train(BATCH_SIZE)\n",
    "            \n",
    "        step_count += 1\n",
    "        \n",
    "    if episode % PRINT_EVERY == 0:\n",
    "        print(\"Episode:\",episode, \" steps:\",step_count, \" episode reward:\",episode_score, \" epsilon:\",epsilon,\" explore,exploit counts:\",agent.get_explore_explit_counts())\n",
    "    \n",
    "    episodes_rewards.append(episode_score)\n",
    "    last_n_episode_rewards = np.mean(episodes_rewards[-DESIRED_EPISODES_AVERAGE:])\n",
    "    \n",
    "    if last_n_episode_rewards >= DESIRED_AVERAGE:\n",
    "        print(\"Solved in \",episode, \" episodes \")\n",
    "        checkpoint_name = \"checkpoint_solved_\"+str(episode)+\".pth\"\n",
    "        torch.save(agent.q_network_local.state_dict(), checkpoint_name)\n",
    "        solved = True\n",
    "        break\n",
    "    \n",
    "    epsilon = max(END_EPSILON, EPSILON_DECAY*epsilon)\n",
    "    \n",
    "if not solved:\n",
    "    checkpoint_name = \"checkpoint_not_solved_\"+str(episode)+\".pth\"\n",
    "    torch.save(agent.q_network_local.state_dict(), checkpoint_name)\n",
    "\n",
    "print(\"Last \", DESIRED_EPISODES_AVERAGE,\" average reward:\",last_n_episode_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(episodes_rewards)), episodes_rewards)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See it trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0  steps: 300  episode reward: 19.0  epsilon: 0.013016701955201824  explore,exploit counts: (0, 300)\n",
      "Episode: 1  steps: 300  episode reward: 16.0  epsilon: 0.013016701955201824  explore,exploit counts: (0, 300)\n",
      "Episode: 2  steps: 300  episode reward: 0.0  epsilon: 0.013016701955201824  explore,exploit counts: (0, 300)\n",
      "Episode: 3  steps: 300  episode reward: 4.0  epsilon: 0.013016701955201824  explore,exploit counts: (0, 300)\n",
      "Episode: 4  steps: 300  episode reward: 17.0  epsilon: 0.013016701955201824  explore,exploit counts: (0, 300)\n",
      "Last  5  average reward: 11.2\n"
     ]
    }
   ],
   "source": [
    "episodes_rewards = []\n",
    "solved = False\n",
    "EPISODES = 5\n",
    "DESIRED_EPISODES_AVERAGE = EPISODES\n",
    "for episode in range(EPISODES):\n",
    "    finished = False\n",
    "    step_count = 0\n",
    "    episode_score = 0\n",
    "    \n",
    "    agent.reset_explore_exploit_counts()\n",
    "    \n",
    "    \n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    \n",
    "    while not finished: #and step_count < MAX_STEPS:\n",
    "        action = agent.act(state,0) #0 epsilon to exploit only \n",
    "\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        finished = env_info.local_done[0]\n",
    "        \n",
    "        episode_score += reward\n",
    "        state = next_state\n",
    "            \n",
    "        step_count += 1\n",
    "        \n",
    "\n",
    "    print(\"Episode:\",episode, \" steps:\",step_count, \" episode reward:\",episode_score, \" epsilon:\",epsilon,\" explore,exploit counts:\",agent.get_explore_explit_counts())\n",
    "    \n",
    "    episodes_rewards.append(episode_score)\n",
    "    last_n_episode_rewards = np.mean(episodes_rewards[-DESIRED_EPISODES_AVERAGE:])\n",
    "    \n",
    "print(\"Last \", DESIRED_EPISODES_AVERAGE,\" average reward:\",last_n_episode_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
